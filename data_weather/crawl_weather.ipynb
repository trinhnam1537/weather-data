{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c31862-3fa5-43ca-be84-77a438ab43b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Äang crawl dá»¯ liá»‡u tá»« ha-noi\n",
      "Äang crawl dá»¯ liá»‡u tá»« ho-chi-minh\n",
      "Äang crawl dá»¯ liá»‡u tá»« da-nang\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸŒ¤ï¸ Crawling weather data:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:42<01:25, 42.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ÄÃ£ lÆ°u dá»¯ liá»‡u ha-noi vÃ o D:\\hust_materials\\DE\\weather\\Big_data_project\\data_weather\\ha-noi.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸŒ¤ï¸ Crawling weather data:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:44<00:18, 18.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ÄÃ£ lÆ°u dá»¯ liá»‡u ho-chi-minh vÃ o D:\\hust_materials\\DE\\weather\\Big_data_project\\data_weather\\ho-chi-minh.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸŒ¤ï¸ Crawling weather data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:47<00:00, 15.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ÄÃ£ lÆ°u dá»¯ liá»‡u da-nang vÃ o D:\\hust_materials\\DE\\weather\\Big_data_project\\data_weather\\da-nang.csv\n",
      "\n",
      "âœ… ÄÃ£ crawl thÃ nh cÃ´ng: 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, WebDriverException\n",
    "\n",
    "def scrape_weather_to_df(name):\n",
    "    # Set up options Ä‘á»ƒ giáº£m tÃ i nguyÃªn sá»­ dá»¥ng\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--disable-gpu')\n",
    "    options.add_argument('--disable-extensions')\n",
    "    options.add_argument('--disable-infobars')\n",
    "    options.add_argument('--disable-notifications')\n",
    "    options.add_argument('--blink-settings=imagesEnabled=false')  # Táº¯t táº£i hÃ¬nh áº£nh\n",
    "    \n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    url = f\"https://www.worldweatheronline.com/{name}-weather-history/vn.aspx\"\n",
    "    driver.get(url)\n",
    "    \n",
    "    data = []\n",
    "    try:\n",
    "        allow_cookies = WebDriverWait(driver, 15).until(\n",
    "            EC.element_to_be_clickable((By.ID, \"CybotCookiebotDialogBodyButtonAccept\"))\n",
    "        )\n",
    "        allow_cookies.click()\n",
    "        time.sleep(1)\n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        pass\n",
    "    \n",
    "    record_keys = ['Time', 'Weather', 'Temp', 'Rain', 'Cloud', 'Pressure', 'Wind', 'Gust']\n",
    "    date = datetime.datetime(2025, 4, 2)\n",
    "    end_date = datetime.datetime(2025, 4, 5)\n",
    "    \n",
    "    try:\n",
    "        while date < end_date:\n",
    "            date_str = date.strftime('%Y-%m-%d')\n",
    "            try:\n",
    "                input_date = WebDriverWait(driver, 7).until(\n",
    "                    EC.presence_of_element_located((By.ID, 'ctl00_MainContentHolder_txtPastDate'))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].value = arguments[1];\", input_date, date_str)\n",
    "                submit_date = driver.find_element(By.ID, 'ctl00_MainContentHolder_butShowPastWeather')\n",
    "                submit_date.click()\n",
    "            except WebDriverException:\n",
    "                date += datetime.timedelta(days=1)\n",
    "                continue\n",
    "            \n",
    "            time.sleep(1)\n",
    "            \n",
    "            tables = driver.find_element(By.XPATH, \"/html/body/form/div[3]/section/div/div/div/div[3]/div[1]/div/div[3]/table/tbody\")\n",
    "    \n",
    "            all_rows = tables.find_elements(By.TAG_NAME, \"tr\")\n",
    "            rows = all_rows[2:10] \n",
    "            \n",
    "            for row in rows:\n",
    "                try:\n",
    "                    cells = row.find_elements(By.CLASS_NAME, \"days-details-row-item1\")\n",
    "                    rains = row.find_elements(By.CLASS_NAME, \"days-rain-number\")\n",
    "                    rain = rains[0].text\n",
    "                    weather_img = cells[1].find_element(By.TAG_NAME, \"img\")\n",
    "                    weather = weather_img.get_attribute(\"title\")\n",
    "                    \n",
    "                    values = [cells[0].text.strip(), weather, cells[2].text.strip(), rain, cells[3].text.strip(), \n",
    "                            cells[4].text.strip(), cells[5].text.strip(), cells[6].text.strip()]\n",
    "                    \n",
    "                    if values:\n",
    "                        data.append([date_str] + values)\n",
    "                except Exception:\n",
    "                    continue\n",
    "            \n",
    "            date += datetime.timedelta(days=1)\n",
    "    finally:\n",
    "        driver.quit()\n",
    "    \n",
    "    if data:\n",
    "        df = pd.DataFrame(data, columns=[\"Date\"] + record_keys)\n",
    "        return df\n",
    "    else:\n",
    "        return pd.DataFrame(columns=[\"Date\"] + record_keys)\n",
    "\n",
    "def process_location(name, output_dir):\n",
    "    try:\n",
    "        print(f\"Äang crawl dá»¯ liá»‡u tá»« {name}\")\n",
    "        df = scrape_weather_to_df(name)\n",
    "        filename = os.path.join(output_dir, f\"{name}.csv\")\n",
    "        df.to_csv(filename, index=False)\n",
    "        return f\"âœ… ÄÃ£ lÆ°u dá»¯ liá»‡u {name} vÃ o {filename}\", name, True\n",
    "    except Exception as e:\n",
    "        return f\" Lá»—i khi crawl {name}: {e}\", name, False\n",
    "\n",
    "def main():\n",
    "    output_dir = r\"D:\\hust_materials\\DE\\weather\\Big_data_project\\data_weather\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    name_tinh_process = [\"ha-noi\", \"ho-chi-minh-city\", \"da-nang\"] \n",
    "    \n",
    "   \n",
    "    max_workers = 3  \n",
    "    \n",
    "    results = []\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Gá»­i cÃ¡c tÃ¡c vá»¥\n",
    "        future_to_name = {\n",
    "            executor.submit(process_location, name, output_dir): name \n",
    "            for name in name_tinh_process\n",
    "        }\n",
    "        \n",
    "        # Hiá»ƒn thá»‹ tiáº¿n trÃ¬nh\n",
    "        with tqdm(total=len(name_tinh_process), desc=\" Crawling weather data\") as pbar:\n",
    "            for future in concurrent.futures.as_completed(future_to_name):\n",
    "                name = future_to_name[future]\n",
    "                try:\n",
    "                    message, location, success = future.result()\n",
    "                    print(message)\n",
    "                    results.append((location, success))\n",
    "                except Exception as e:\n",
    "                    print(f\" Lá»—i vá»›i {name}: {e}\")\n",
    "                    results.append((name, False))\n",
    "                pbar.update(1)\n",
    "    \n",
    "   \n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0028f987-acde-468f-99c8-c3f0794d63f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
