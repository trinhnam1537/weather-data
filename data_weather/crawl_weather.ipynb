{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c31862-3fa5-43ca-be84-77a438ab43b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang crawl dữ liệu từ ha-noi\n",
      "Đang crawl dữ liệu từ ho-chi-minh\n",
      "Đang crawl dữ liệu từ da-nang\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🌤️ Crawling weather data:  33%|███▎      | 1/3 [00:42<01:25, 42.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã lưu dữ liệu ha-noi vào D:\\hust_materials\\DE\\weather\\Big_data_project\\data_weather\\ha-noi.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🌤️ Crawling weather data:  67%|██████▋   | 2/3 [00:44<00:18, 18.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã lưu dữ liệu ho-chi-minh vào D:\\hust_materials\\DE\\weather\\Big_data_project\\data_weather\\ho-chi-minh.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🌤️ Crawling weather data: 100%|██████████| 3/3 [00:47<00:00, 15.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã lưu dữ liệu da-nang vào D:\\hust_materials\\DE\\weather\\Big_data_project\\data_weather\\da-nang.csv\n",
      "\n",
      "✅ Đã crawl thành công: 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, WebDriverException\n",
    "\n",
    "def scrape_weather_to_df(name):\n",
    "    # Set up options để giảm tài nguyên sử dụng\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--disable-gpu')\n",
    "    options.add_argument('--disable-extensions')\n",
    "    options.add_argument('--disable-infobars')\n",
    "    options.add_argument('--disable-notifications')\n",
    "    options.add_argument('--blink-settings=imagesEnabled=false')  # Tắt tải hình ảnh\n",
    "    \n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    url = f\"https://www.worldweatheronline.com/{name}-weather-history/vn.aspx\"\n",
    "    driver.get(url)\n",
    "    \n",
    "    data = []\n",
    "    try:\n",
    "        allow_cookies = WebDriverWait(driver, 15).until(\n",
    "            EC.element_to_be_clickable((By.ID, \"CybotCookiebotDialogBodyButtonAccept\"))\n",
    "        )\n",
    "        allow_cookies.click()\n",
    "        time.sleep(1)\n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        pass\n",
    "    \n",
    "    record_keys = ['Time', 'Weather', 'Temp', 'Rain', 'Cloud', 'Pressure', 'Wind', 'Gust']\n",
    "    date = datetime.datetime(2025, 4, 2)\n",
    "    end_date = datetime.datetime(2025, 4, 5)\n",
    "    \n",
    "    try:\n",
    "        while date < end_date:\n",
    "            date_str = date.strftime('%Y-%m-%d')\n",
    "            try:\n",
    "                input_date = WebDriverWait(driver, 7).until(\n",
    "                    EC.presence_of_element_located((By.ID, 'ctl00_MainContentHolder_txtPastDate'))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].value = arguments[1];\", input_date, date_str)\n",
    "                submit_date = driver.find_element(By.ID, 'ctl00_MainContentHolder_butShowPastWeather')\n",
    "                submit_date.click()\n",
    "            except WebDriverException:\n",
    "                date += datetime.timedelta(days=1)\n",
    "                continue\n",
    "            \n",
    "            time.sleep(1)\n",
    "            \n",
    "            tables = driver.find_element(By.XPATH, \"/html/body/form/div[3]/section/div/div/div/div[3]/div[1]/div/div[3]/table/tbody\")\n",
    "    \n",
    "            all_rows = tables.find_elements(By.TAG_NAME, \"tr\")\n",
    "            rows = all_rows[2:10] \n",
    "            \n",
    "            for row in rows:\n",
    "                try:\n",
    "                    cells = row.find_elements(By.CLASS_NAME, \"days-details-row-item1\")\n",
    "                    rains = row.find_elements(By.CLASS_NAME, \"days-rain-number\")\n",
    "                    rain = rains[0].text\n",
    "                    weather_img = cells[1].find_element(By.TAG_NAME, \"img\")\n",
    "                    weather = weather_img.get_attribute(\"title\")\n",
    "                    \n",
    "                    values = [cells[0].text.strip(), weather, cells[2].text.strip(), rain, cells[3].text.strip(), \n",
    "                            cells[4].text.strip(), cells[5].text.strip(), cells[6].text.strip()]\n",
    "                    \n",
    "                    if values:\n",
    "                        data.append([date_str] + values)\n",
    "                except Exception:\n",
    "                    continue\n",
    "            \n",
    "            date += datetime.timedelta(days=1)\n",
    "    finally:\n",
    "        driver.quit()\n",
    "    \n",
    "    if data:\n",
    "        df = pd.DataFrame(data, columns=[\"Date\"] + record_keys)\n",
    "        return df\n",
    "    else:\n",
    "        return pd.DataFrame(columns=[\"Date\"] + record_keys)\n",
    "\n",
    "def process_location(name, output_dir):\n",
    "    try:\n",
    "        print(f\"Đang crawl dữ liệu từ {name}\")\n",
    "        df = scrape_weather_to_df(name)\n",
    "        filename = os.path.join(output_dir, f\"{name}.csv\")\n",
    "        df.to_csv(filename, index=False)\n",
    "        return f\"✅ Đã lưu dữ liệu {name} vào {filename}\", name, True\n",
    "    except Exception as e:\n",
    "        return f\" Lỗi khi crawl {name}: {e}\", name, False\n",
    "\n",
    "def main():\n",
    "    output_dir = r\"D:\\hust_materials\\DE\\weather\\Big_data_project\\data_weather\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    name_tinh_process = [\"ha-noi\", \"ho-chi-minh-city\", \"da-nang\"] \n",
    "    \n",
    "   \n",
    "    max_workers = 3  \n",
    "    \n",
    "    results = []\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Gửi các tác vụ\n",
    "        future_to_name = {\n",
    "            executor.submit(process_location, name, output_dir): name \n",
    "            for name in name_tinh_process\n",
    "        }\n",
    "        \n",
    "        # Hiển thị tiến trình\n",
    "        with tqdm(total=len(name_tinh_process), desc=\" Crawling weather data\") as pbar:\n",
    "            for future in concurrent.futures.as_completed(future_to_name):\n",
    "                name = future_to_name[future]\n",
    "                try:\n",
    "                    message, location, success = future.result()\n",
    "                    print(message)\n",
    "                    results.append((location, success))\n",
    "                except Exception as e:\n",
    "                    print(f\" Lỗi với {name}: {e}\")\n",
    "                    results.append((name, False))\n",
    "                pbar.update(1)\n",
    "    \n",
    "   \n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0028f987-acde-468f-99c8-c3f0794d63f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
